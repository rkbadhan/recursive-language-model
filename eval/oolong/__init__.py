"""
OOLONG Benchmark Evaluation for RLM.

This module provides tools to evaluate Recursive Language Models on the
OOLONG benchmark, which tests long-context aggregation and reasoning capabilities.

Main components:
- eval.py: Main evaluation script
- test_integration.py: Integration tests

Usage:
    python eval/oolong/eval.py --dataset synth --max-examples 10
    python eval/oolong/test_integration.py
"""
